{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1411a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Turing\n",
    "using StatsPlots\n",
    "using Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72c6119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model (generic function with 2 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function model(data)\n",
    "    rt_max = mean(data) # Max RT\n",
    "    return rt_max\n",
    "    rt_max = 1000\n",
    "    d_max = maximum(data.distance) # Max distance\n",
    "    d_max = length(data)\n",
    "    distance = [1:d_max]\n",
    "    \n",
    "    # Priors\n",
    "    num_cps ~ Uniform(1,3) # Number of changepoints\n",
    "    mu = DiscreteUniform.(rand(1:rt_max,num_cps+1)) # Means for each interval\n",
    "    sigma ~ Normal(0,100)\n",
    "    \n",
    "    # The changepoints\n",
    "    cps = [Uniform(0,d_max)] # Dealing with one changepoint\n",
    "    if num_cps > 1 # Dealing with >1 changepoint\n",
    "        for i in num_cps-1\n",
    "            # Sample new Unif and add to vector\n",
    "            push!(cps, rand(Uniform(cps[i], d_max))) \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Set up indexing variable for cps\n",
    "    cp_idx = 1\n",
    "    # Sample stationary intervals\n",
    "    for d in 1:d_max\n",
    "        if d < cps[cp_idx]\n",
    "            data[d] ~ Normal(mu[cp_idx],sigma) # Make this a linear funciton of distance\n",
    "        else\n",
    "            cp_idx += 1\n",
    "            data[d] ~ Normal(mu[cp_idx],sigma) # Make this a linear funciton of distance\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8550ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "num_cps_true = 2\n",
    "cps = [100,500]\n",
    "mu1 = 100\n",
    "mu2 = 300\n",
    "mu3 = 500\n",
    "sigma = 20\n",
    "\n",
    "x = vcat(\n",
    "    rand(Normal(mu1,sigma), cps[1]), \n",
    "    rand(Normal(mu2,sigma), cps[2]-cps[1]),\n",
    "    rand(Normal(mu3,sigma), 1000-cps[2]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29bfce2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000-element Vector{Float64}:\n",
       "  62.9809412479054\n",
       "  99.80685001925603\n",
       " 103.94307356802149\n",
       "  86.37687024608789\n",
       "  72.99187164007742\n",
       " 102.1573859717075\n",
       " 122.73510787190139\n",
       "  76.95684437296535\n",
       " 109.31393372204853\n",
       "  86.98994031146688\n",
       "  98.62518405536875\n",
       " 111.52239112148223\n",
       "  89.5144701011275\n",
       "   ⋮\n",
       " 506.75645125273616\n",
       " 507.60796312669834\n",
       " 502.4795315347952\n",
       " 535.8840781460851\n",
       " 484.8778275298654\n",
       " 476.98906765831657\n",
       " 458.2724893738179\n",
       " 476.05556624864715\n",
       " 536.293318630134\n",
       " 515.2238653854439\n",
       " 486.0034519538988\n",
       " 530.6809991530472"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b0d9ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching phasepoint(::Random._GLOBAL_RNG, ::Vector{Any}, ::AdvancedHMC.Hamiltonian{AdvancedHMC.DiagEuclideanMetric{Float64, Vector{Float64}}, Base.Fix1{typeof(LogDensityProblems.logdensity), LogDensityProblems.ForwardDiffLogDensity{Turing.LogDensityFunction{DynamicPPL.TypedVarInfo{NamedTuple{(), Tuple{}}, Float64}, DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, ForwardDiff.GradientConfig{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0}}}}}, Turing.Inference.var\"#∂logπ∂θ#44\"{LogDensityProblems.ForwardDiffLogDensity{Turing.LogDensityFunction{DynamicPPL.TypedVarInfo{NamedTuple{(), Tuple{}}, Float64}, DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, ForwardDiff.GradientConfig{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0}}}}}})\n\u001b[0mClosest candidates are:\n\u001b[0m  phasepoint(::Union{Random.AbstractRNG, AbstractVector{<:Random.AbstractRNG}}, \u001b[91m::AbstractVecOrMat{T}\u001b[39m, ::AdvancedHMC.Hamiltonian) where T<:Real at ~/.julia/packages/AdvancedHMC/iWHPQ/src/hamiltonian.jl:153\n\u001b[0m  phasepoint(\u001b[91m::AdvancedHMC.Hamiltonian\u001b[39m, ::T, \u001b[91m::T\u001b[39m; ℓπ, ℓκ) where T<:(AbstractVecOrMat) at ~/.julia/packages/AdvancedHMC/iWHPQ/src/hamiltonian.jl:76\n\u001b[0m  phasepoint(\u001b[91m::AdvancedHMC.Hamiltonian\u001b[39m, ::T1, \u001b[91m::T2\u001b[39m; r, ℓπ, ℓκ) where {T1<:(AbstractVecOrMat), T2<:(AbstractVecOrMat)} at ~/.julia/packages/AdvancedHMC/iWHPQ/src/hamiltonian.jl:88",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching phasepoint(::Random._GLOBAL_RNG, ::Vector{Any}, ::AdvancedHMC.Hamiltonian{AdvancedHMC.DiagEuclideanMetric{Float64, Vector{Float64}}, Base.Fix1{typeof(LogDensityProblems.logdensity), LogDensityProblems.ForwardDiffLogDensity{Turing.LogDensityFunction{DynamicPPL.TypedVarInfo{NamedTuple{(), Tuple{}}, Float64}, DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, ForwardDiff.GradientConfig{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0}}}}}, Turing.Inference.var\"#∂logπ∂θ#44\"{LogDensityProblems.ForwardDiffLogDensity{Turing.LogDensityFunction{DynamicPPL.TypedVarInfo{NamedTuple{(), Tuple{}}, Float64}, DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, DynamicPPL.DefaultContext}, ForwardDiff.GradientConfig{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0, Vector{ForwardDiff.Dual{ForwardDiff.Tag{Turing.TuringTag, Any}, Any, 0}}}}}})\n\u001b[0mClosest candidates are:\n\u001b[0m  phasepoint(::Union{Random.AbstractRNG, AbstractVector{<:Random.AbstractRNG}}, \u001b[91m::AbstractVecOrMat{T}\u001b[39m, ::AdvancedHMC.Hamiltonian) where T<:Real at ~/.julia/packages/AdvancedHMC/iWHPQ/src/hamiltonian.jl:153\n\u001b[0m  phasepoint(\u001b[91m::AdvancedHMC.Hamiltonian\u001b[39m, ::T, \u001b[91m::T\u001b[39m; ℓπ, ℓκ) where T<:(AbstractVecOrMat) at ~/.julia/packages/AdvancedHMC/iWHPQ/src/hamiltonian.jl:76\n\u001b[0m  phasepoint(\u001b[91m::AdvancedHMC.Hamiltonian\u001b[39m, ::T1, \u001b[91m::T2\u001b[39m; r, ℓπ, ℓκ) where {T1<:(AbstractVecOrMat), T2<:(AbstractVecOrMat)} at ~/.julia/packages/AdvancedHMC/iWHPQ/src/hamiltonian.jl:88",
      "",
      "Stacktrace:",
      "  [1] initialstep(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, spl::DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, vi::DynamicPPL.TypedVarInfo{NamedTuple{(), Tuple{}}, Float64}; init_params::Nothing, nadapts::Int64, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Turing.Inference ~/.julia/packages/Turing/KOb5J/src/inference/hmc.jl:169",
      "  [2] step(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, spl::DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}; resume_from::Nothing, init_params::Nothing, kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:nadapts,), Tuple{Int64}}})",
      "    @ DynamicPPL ~/.julia/packages/DynamicPPL/xKo8W/src/sampler.jl:111",
      "  [3] macro expansion",
      "    @ ~/.julia/packages/AbstractMCMC/fnRmh/src/sample.jl:120 [inlined]",
      "  [4] macro expansion",
      "    @ ~/.julia/packages/ProgressLogging/6KXlp/src/ProgressLogging.jl:328 [inlined]",
      "  [5] (::AbstractMCMC.var\"#21#22\"{Bool, String, Nothing, Int64, Int64, Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:nadapts,), Tuple{Int64}}}, Random._GLOBAL_RNG, DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, Int64, Int64})()",
      "    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/fnRmh/src/logging.jl:12",
      "  [6] with_logstate(f::Function, logstate::Any)",
      "    @ Base.CoreLogging ./logging.jl:511",
      "  [7] with_logger(f::Function, logger::LoggingExtras.TeeLogger{Tuple{LoggingExtras.EarlyFilteredLogger{ConsoleProgressMonitor.ProgressLogger, AbstractMCMC.var\"#1#3\"{Module}}, LoggingExtras.EarlyFilteredLogger{Base.CoreLogging.SimpleLogger, AbstractMCMC.var\"#2#4\"{Module}}}})",
      "    @ Base.CoreLogging ./logging.jl:623",
      "  [8] with_progresslogger(f::Function, _module::Module, logger::Base.CoreLogging.SimpleLogger)",
      "    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/fnRmh/src/logging.jl:36",
      "  [9] macro expansion",
      "    @ ~/.julia/packages/AbstractMCMC/fnRmh/src/logging.jl:11 [inlined]",
      " [10] mcmcsample(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, N::Int64; progress::Bool, progressname::String, callback::Nothing, discard_initial::Int64, thinning::Int64, chain_type::Type, kwargs::Base.Pairs{Symbol, Int64, Tuple{Symbol}, NamedTuple{(:nadapts,), Tuple{Int64}}})",
      "    @ AbstractMCMC ~/.julia/packages/AbstractMCMC/fnRmh/src/sample.jl:111",
      " [11] sample(rng::Random._GLOBAL_RNG, model::DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, sampler::DynamicPPL.Sampler{NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}}, N::Int64; chain_type::Type, resume_from::Nothing, progress::Bool, nadapts::Int64, discard_adapt::Bool, discard_initial::Int64, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ Turing.Inference ~/.julia/packages/Turing/KOb5J/src/inference/hmc.jl:133",
      " [12] sample",
      "    @ ~/.julia/packages/Turing/KOb5J/src/inference/hmc.jl:103 [inlined]",
      " [13] #sample#2",
      "    @ ~/.julia/packages/Turing/KOb5J/src/inference/Inference.jl:145 [inlined]",
      " [14] sample",
      "    @ ~/.julia/packages/Turing/KOb5J/src/inference/Inference.jl:138 [inlined]",
      " [15] #sample#1",
      "    @ ~/.julia/packages/Turing/KOb5J/src/inference/Inference.jl:135 [inlined]",
      " [16] sample(model::DynamicPPL.Model{typeof(model), (:data,), (), (), Tuple{Vector{Float64}}, Tuple{}, DynamicPPL.DefaultContext}, alg::NUTS{Turing.Essential.ForwardDiffAD{0}, (), AdvancedHMC.DiagEuclideanMetric}, N::Int64)",
      "    @ Turing.Inference ~/.julia/packages/Turing/KOb5J/src/inference/Inference.jl:129",
      " [17] top-level scope",
      "    @ In[13]:1",
      " [18] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [19] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "chain = sample(model(x), NUTS(), 5000)\n",
    "\n",
    "plot(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614050c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
